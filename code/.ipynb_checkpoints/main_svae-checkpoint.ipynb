{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE for ranking items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Formalization\n",
    "\n",
    "For each user $u \\in U$, we have a set, $P_u$ = { $(m_1, m_2)$ | $rating_u^{m_1}$ > $rating_u^{m_2}$) } \n",
    "\n",
    "$P$ =  $\\bigcup\\limits_{\\forall u \\; \\in \\; U} P_u$\n",
    "\n",
    "$\\forall (u, m_1, m_2) \\in P, $ we send two inputs, $x_1 = u \\Vert m_1$ and $x_2 = u \\Vert m_2$ to a VAE (with the same parameters).\n",
    "\n",
    "We expect the VAE's encoder to produce $z_1$ (sampled from the distribution: $(\\mu_1 , \\Sigma_1$)) from $x_1$ ; and similarly $z_2$ from $x_2$ using the parameters $\\theta$.\n",
    "\n",
    "The decoder network is expected to learn a mapping function $f_{\\phi}$ from $z_1$ to $m_1$.\n",
    "\n",
    "We currently have 2 ideas for the decoder network:\n",
    "1. Using two sets of network parameters, $\\phi$ and $\\psi$ for $z_1$ and $z_2$ respectively.\n",
    "2. Using $\\phi$ for both $z_1$ and $z_2$.\n",
    "\n",
    "For ranking the pairs of movies, we have another network:\n",
    "1. The input of the network is $z_1 \\Vert z_2$, \n",
    "2. Is expected to learn a mapping, $f_{\\delta}$ to a bernoulli distribution over True/False, modelling $rating_u^{m_1} > rating_u^{m_2}$.\n",
    "\n",
    "## Loss Function\n",
    "\n",
    "$$Loss \\; = \\; KL( \\, \\phi(z_1 \\vert x_1) \\Vert {\\rm I\\!N(0, I)} \\, ) \\; + \\; KL( \\, \\psi(z_2 \\vert x_2) \\Vert {\\rm I\\!N(0, I)} \\, ) \\; - \\; \\sum_{i} m_{1i} \\, log( \\, f_{\\phi}(z_1)_i ) \\; - \\; \\sum_{i} m_{2i} \\, log( \\, f_{\\psi}(z_2)_i ) \\; - \\; f_{\\delta}(z_1 \\Vert z_2) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utlity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LongTensor = torch.LongTensor\n",
    "FloatTensor = torch.FloatTensor\n",
    "\n",
    "is_cuda_available = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda_available: \n",
    "    print(\"Using CUDA...\\n\")\n",
    "    LongTensor = torch.cuda.LongTensor\n",
    "    FloatTensor = torch.cuda.FloatTensor\n",
    "    \n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def save_obj_json(obj, name):\n",
    "    with open(name + '.json', 'w') as f:\n",
    "        json.dump(obj, f)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def load_obj_json(name):\n",
    "    with open(name + '.json', 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def file_write(log_file, s):\n",
    "    print(s)\n",
    "    f = open(log_file, 'a')\n",
    "    f.write(s+'\\n')\n",
    "    f.close()\n",
    "\n",
    "def clear_log_file(log_file):\n",
    "    f = open(log_file, 'w')\n",
    "    f.write('')\n",
    "    f.close()\n",
    "\n",
    "def pretty_print(h):\n",
    "    print(\"{\")\n",
    "    for key in h:\n",
    "        print(' ' * 4 + str(key) + ': ' + h[key])\n",
    "    print('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "NOTES:\n",
    "\n",
    "- Try having two different layers for mu and sigma\n",
    "- Never using dropout\n",
    "- Not using L2 Norm at input\n",
    "\n",
    "'''\n",
    "\n",
    "hyper_params = {\n",
    "#     'data_base': '../saved_data/netflix/pro_sg/',\n",
    "#     'project_name': 'svae_netflix',\n",
    "#     'data_base': '../saved_data/ml-1m/pro_sg/',\n",
    "#     'project_name': 'svae_ml1m',\n",
    "    'data_base': '../saved_data/netflix-full/pro_sg/',\n",
    "    'project_name': 'svae_netflix_full',\n",
    "#     'data_base': '../saved_data/netflix-good-sample/pro_sg/',\n",
    "#     'project_name': 'svae_netflix_good_sample',\n",
    "    'model_file_name': '',\n",
    "    'log_file': '',\n",
    "    'history_split_test': [0.8, 0.2], # Part of test history to train on : Part of test history to test\n",
    "\n",
    "    'learning_rate': 0.01, # learning rate is required only if optimizer is adagrad\n",
    "    'optimizer': 'adam',\n",
    "    'weight_decay': float(5e-3),\n",
    "\n",
    "    'epochs': 25,\n",
    "    'batch_size': 1,\n",
    "    \n",
    "    'item_embed_size': 256,\n",
    "    'rnn_size': 200,\n",
    "    'hidden_size': 150,\n",
    "    'latent_size': 64,\n",
    "    'loss_type': 'next_k', # [predict_next, same, prefix, postfix, exp_decay, next_k]\n",
    "    'next_k': 4,\n",
    "    #'conditional': True,\n",
    "    #'attention_context': 4,\n",
    "\n",
    "    'number_users_to_keep': 1000000000,\n",
    "    'batch_log_interval': 1000,\n",
    "    'train_cp_users': 200,\n",
    "    'exploding_clip': 0.25,\n",
    "}\n",
    "\n",
    "file_name = '_optimizer_' + str(hyper_params['optimizer'])\n",
    "if hyper_params['optimizer'] == 'adagrad':\n",
    "    file_name += '_lr_' + str(hyper_params['learning_rate'])\n",
    "file_name += '_weight_decay_' + str(hyper_params['weight_decay'])\n",
    "file_name += '_loss_type_' + str(hyper_params['loss_type'])\n",
    "# file_name += '_k_' + str(hyper_params['next_k'])\n",
    "#file_name += '_conditional_' + str(hyper_params['conditional'])\n",
    "file_name += '_item_embed_size_' + str(hyper_params['item_embed_size'])\n",
    "file_name += '_rnn_size_' + str(hyper_params['rnn_size'])\n",
    "file_name += '_latent_size_' + str(hyper_params['latent_size'])\n",
    "#file_name += '_history_split_' + str(hyper_params['history_split_test'][0])\n",
    "\n",
    "hyper_params['log_file'] = '../saved_logs/' + hyper_params['project_name'] + '_log' + file_name + '.txt'\n",
    "hyper_params['model_file_name'] = '../saved_models/' + hyper_params['project_name'] + '_model' + file_name + '.pt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data(hyper_params):\n",
    "    \n",
    "    file_write(hyper_params['log_file'], \"Started reading data file\")\n",
    "    \n",
    "    f = open(hyper_params['data_base'] + 'train.csv')\n",
    "    lines_train = f.readlines()[1:]\n",
    "    \n",
    "    f = open(hyper_params['data_base'] + 'test_tr.csv')\n",
    "    lines_test_tr = f.readlines()[1:]\n",
    "    \n",
    "    f = open(hyper_params['data_base'] + 'test_te.csv')\n",
    "    lines_test_te = f.readlines()[1:]\n",
    "    \n",
    "    unique_sid = list()\n",
    "    with open(hyper_params['data_base'] + 'unique_sid.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            unique_sid.append(line.strip())\n",
    "    num_items = len(unique_sid)\n",
    "    \n",
    "    file_write(hyper_params['log_file'], \"Data Files loaded!\")\n",
    "\n",
    "    train_reader = DataReader(hyper_params, lines_train, None, num_items, True)\n",
    "    test_reader = DataReader(hyper_params, lines_test_tr, lines_test_te, num_items, False)\n",
    "\n",
    "    return train_reader, test_reader, num_items\n",
    "\n",
    "def load_data2(hyper_params):\n",
    "    \n",
    "    file_write(hyper_params['log_file'], \"Started reading data file\")\n",
    "    \n",
    "    train = pd.read_csv(hyper_params['data_base'] + 'train.csv')\n",
    "    train.columns = ['user', 'movie', 'rating']\n",
    "    \n",
    "    test_train = pd.read_csv(hyper_params['data_base'] + 'test_tr.csv')\n",
    "    test_train.columns = ['user', 'movie', 'rating']\n",
    "    \n",
    "    test_test = pd.read_csv(hyper_params['data_base'] + 'test_te.csv')\n",
    "    test_test.columns = ['user', 'movie', 'rating']\n",
    "    \n",
    "    # Starting test users' id from 0\n",
    "    test_train['user'] = test_train['user'] - min(test_train['user'])\n",
    "    test_test['user'] = test_test['user'] - min(test_test['user'])\n",
    "    \n",
    "    unique_sid = list()\n",
    "    with open(hyper_params['data_base'] + 'unique_sid.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            unique_sid.append(line.strip())\n",
    "    num_items = len(unique_sid)\n",
    "    \n",
    "    num_users_train = max(train['user']) + 1\n",
    "    num_users_test = max(test_train['user']) + 1\n",
    "    \n",
    "    file_write(hyper_params['log_file'], \"Data Files loaded!\")\n",
    "\n",
    "    train_reader = DataReader(hyper_params, train, None, num_users_train, num_items, True)\n",
    "    test_reader = DataReader(hyper_params, test_train, test_test, num_users_test, num_items, False)\n",
    "\n",
    "    return train_reader, test_reader, num_items\n",
    "\n",
    "# class DataReader:\n",
    "#     def __init__(self, hyper_params, data_train, data_test, num_users, num_items, is_training):\n",
    "#         self.hyper_params = hyper_params\n",
    "#         self.batch_size = hyper_params['batch_size']\n",
    "#         self.num_users = num_users\n",
    "#         self.num_items = num_items\n",
    "#         self.data_train = data_train\n",
    "#         self.data_test = data_test\n",
    "#         self.is_training = is_training\n",
    "#         self.all_users = []\n",
    "        \n",
    "#         self.prep()\n",
    "#         self.number()\n",
    "\n",
    "#     def prep(self):\n",
    "#         self.data = []\n",
    "#         for i in range(self.num_users): self.data.append([])\n",
    "#         for index, row in self.data_train.iterrows():\n",
    "#             self.data[int(row['user'])].append([ int(row['movie']), int(row['rating']) ])\n",
    "        \n",
    "#         if self.is_training == False:\n",
    "#             self.data_te = []\n",
    "#             for i in range(self.num_users): self.data_te.append([])\n",
    "#             for index, row in self.data_test.iterrows():\n",
    "#                 self.data_te[int(row['user'])].append([ int(row['movie']), int(row['rating']) ])\n",
    "        \n",
    "#     def number(self):\n",
    "#         users_done = 0\n",
    "#         count = 0\n",
    "#         y_batch = []\n",
    "\n",
    "#         for user in range(len(self.data)):\n",
    "\n",
    "#             if users_done > self.hyper_params['number_users_to_keep']: break\n",
    "#             users_done += 1\n",
    "\n",
    "#             y_batch.append(0)\n",
    "\n",
    "#             if len(y_batch) == self.batch_size:\n",
    "#                 y_batch = []\n",
    "#                 count += 1\n",
    "\n",
    "#         self.num_b = count\n",
    "\n",
    "class DataReader:\n",
    "    def __init__(self, hyper_params, a, b, num_items, is_training):\n",
    "        self.hyper_params = hyper_params\n",
    "        self.batch_size = hyper_params['batch_size']\n",
    "        \n",
    "        num_users = 0\n",
    "        min_user = 1000000000000000000000000\n",
    "        for line in a:\n",
    "            line = line.strip().split(\",\")\n",
    "            num_users = max(num_users, int(line[0]))\n",
    "            min_user = min(min_user, int(line[0]))\n",
    "        num_users = num_users - min_user + 1\n",
    "        \n",
    "        self.num_users = num_users\n",
    "        self.min_user = min_user\n",
    "        self.num_items = num_items\n",
    "        \n",
    "        self.data_train = a\n",
    "        self.data_test = b\n",
    "        self.is_training = is_training\n",
    "        self.all_users = []\n",
    "        \n",
    "        self.prep()\n",
    "        self.number()\n",
    "\n",
    "    def prep(self):\n",
    "        self.data = []\n",
    "        for i in range(self.num_users): self.data.append([])\n",
    "            \n",
    "        for i in tqdm(range(len(self.data_train))):\n",
    "            line = self.data_train[i]\n",
    "            line = line.strip().split(\",\")\n",
    "            self.data[int(line[0]) - self.min_user].append([ int(line[1]), 1 ])\n",
    "        \n",
    "        if self.is_training == False:\n",
    "            self.data_te = []\n",
    "            for i in range(self.num_users): self.data_te.append([])\n",
    "                \n",
    "            for i in tqdm(range(len(self.data_test))):\n",
    "                line = self.data_test[i]\n",
    "                line = line.strip().split(\",\")\n",
    "                self.data_te[int(line[0]) - self.min_user].append([ int(line[1]), 1 ])\n",
    "        \n",
    "    def number(self):\n",
    "        self.num_b = int(min(len(self.data), self.hyper_params['number_users_to_keep']) / self.batch_size)\n",
    "    \n",
    "    def iter(self):\n",
    "        users_done = 0\n",
    "\n",
    "        x_batch = []\n",
    "        now_at = 0\n",
    "        \n",
    "        user_iterate_order = list(range(len(self.data)))\n",
    "        # np.random.shuffle(user_iterate_order)\n",
    "        \n",
    "        for user in user_iterate_order:\n",
    "\n",
    "            if users_done > self.hyper_params['number_users_to_keep']: break\n",
    "            users_done += 1\n",
    "            \n",
    "            if self.hyper_params['loss_type'] == 'predict_next':\n",
    "                y_batch_s = torch.zeros(self.batch_size, len(self.data[user])-1, self.num_items).cuda()\n",
    "                for timestep in range(len(self.data[user]) - 1):\n",
    "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
    "                        0, LongTensor([ i[0] for i in [ self.data[user][timestep + 1] ] ]), 1.0\n",
    "                    )\n",
    "                x_batch.append([ i[0] for i in self.data[user][:-1] ])\n",
    "                \n",
    "            elif self.hyper_params['loss_type'] == 'next_k':\n",
    "                y_batch_s = torch.zeros(self.batch_size, len(self.data[user])-1, self.num_items).cuda()\n",
    "                for timestep in range(len(self.data[user]) - 1):\n",
    "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
    "                        0, LongTensor([ i[0] for i in self.data[user][timestep + 1:][:self.hyper_params['next_k']] ]), 1.0\n",
    "                    )\n",
    "                x_batch.append([ i[0] for i in self.data[user][:-1] ])\n",
    "            \n",
    "#             elif self.hyper_params['loss_type'] == 'same':\n",
    "#                 x_batch.append([ i[0] for i in self.data[user][:] ])\n",
    "#                 y_batch_s[now_at, :].scatter_(\n",
    "#                     0, LongTensor([ i[0] for i in [ self.data[user][0] ] ]), 1.0\n",
    "#                 )\n",
    "#                 y_batch.append([ i[0] for i in self.data[user][:] ])\n",
    "            \n",
    "#             elif self.hyper_params['loss_type'] == 'prefix':\n",
    "#                 x_batch.append([ i[0] for i in self.data[user][:] ])\n",
    "#                 y_batch_s[now_at, :].scatter_(\n",
    "#                     0, LongTensor([ i[0] for i in [ self.data[user][0] ] ]), 1.0\n",
    "#                 )\n",
    "#                 y_batch.append([ i[0] for i in self.data[user][:] ])\n",
    "            \n",
    "#             elif self.hyper_params['loss_type'] == 'postfix':\n",
    "#                 x_batch.append([ i[0] for i in self.data[user][:] ])\n",
    "#                 y_batch_s[now_at, :].scatter_(\n",
    "#                     0, LongTensor([ i[0] for i in self.data[user][:] ]), 1.0\n",
    "#                 )\n",
    "#                 y_batch.append([ i[0] for i in self.data[user][:] ])\n",
    "                \n",
    "#             elif self.hyper_params['loss_type'] == 'exp_decay':\n",
    "#                 x_batch.append([ i[0] for i in self.data[user][:] ])\n",
    "#                 y_batch_s[now_at, :].scatter_(\n",
    "#                     # 0, LongTensor([ i[0] for i in self.data[user][:] ]), FloatTensor([ np.e ** (-1.0 * i) for i in range(len(self.data[user][:])) ]), \n",
    "#                     0, LongTensor([ i[0] for i in self.data[user][:] ]), FloatTensor([ 1.0 / (i + 1.0) for i in range(len(self.data[user][:])) ]), \n",
    "#                     # 0, LongTensor([ i[0] for i in self.data[user][:] ]), FloatTensor([ 1.0 / np.log2(i + 2.0) for i in range(len(self.data[user][:])) ]), \n",
    "#                 )\n",
    "#                 y_batch.append([ i[0] for i in self.data[user][:] ])\n",
    "            \n",
    "            now_at += 1\n",
    "    \n",
    "            if now_at == self.batch_size:\n",
    "\n",
    "                yield Variable(LongTensor(x_batch)), Variable(y_batch_s, requires_grad=False)\n",
    "\n",
    "                x_batch = []\n",
    "                now_at = 0\n",
    "\n",
    "    def iter_eval(self):\n",
    "\n",
    "        x_batch = []\n",
    "        y_batch_s = torch.zeros(self.batch_size, self.num_items).cuda()\n",
    "        y_batch = []\n",
    "        test_movies, test_movies_r = [], []\n",
    "        now_at = 0\n",
    "        users_done = 0\n",
    "        \n",
    "        for user in range(len(self.data)):\n",
    "            \n",
    "            users_done += 1\n",
    "            if users_done > self.hyper_params['number_users_to_keep']: break\n",
    "            \n",
    "            if self.is_training == True: \n",
    "                split = float(self.hyper_params['history_split_test'][0])\n",
    "                base_predictions_on = self.data[user][:int(split * len(self.data[user]))]\n",
    "                heldout_movies = self.data[user][int(split * len(self.data[user])):]\n",
    "            else:\n",
    "                base_predictions_on = self.data[user]\n",
    "                heldout_movies = self.data_te[user]\n",
    "                \n",
    "            if self.hyper_params['loss_type'] == 'predict_next':\n",
    "                y_batch_s = torch.zeros(self.batch_size, len(base_predictions_on)-1, self.num_items).cuda()\n",
    "                for timestep in range(len(base_predictions_on) - 1):\n",
    "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
    "                        0, LongTensor([ i[0] for i in [ base_predictions_on[timestep + 1] ] ]), 1.0\n",
    "                    )\n",
    "                x_batch.append([ i[0] for i in base_predictions_on[:-1] ])\n",
    "                \n",
    "            elif self.hyper_params['loss_type'] == 'next_k':\n",
    "                y_batch_s = torch.zeros(self.batch_size, len(base_predictions_on)-1, self.num_items).cuda()\n",
    "                for timestep in range(len(base_predictions_on) - 1):\n",
    "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
    "                        0, LongTensor([ i[0] for i in base_predictions_on[timestep + 1:][:self.hyper_params['next_k']] ]), 1.0\n",
    "                    )\n",
    "                x_batch.append([ i[0] for i in base_predictions_on[:-1] ])\n",
    "            \n",
    "#             elif self.hyper_params['loss_type'] == 'same':\n",
    "#                 x_batch.append([ i[0] for i in base_predictions_on[:] ])\n",
    "#                 y_batch_s[now_at, :].scatter_(\n",
    "#                     0, LongTensor([ i[0] for i in [ base_predictions_on[0] ] ]), 1.0\n",
    "#                 )\n",
    "#                 y_batch.append([ i[0] for i in base_predictions_on[:] ])\n",
    "            \n",
    "#             elif self.hyper_params['loss_type'] == 'prefix':\n",
    "#                 x_batch.append([ i[0] for i in base_predictions_on[:] ])\n",
    "#                 y_batch_s[now_at, :].scatter_(\n",
    "#                     0, LongTensor([ i[0] for i in [ base_predictions_on[0] ] ]), 1.0\n",
    "#                 )\n",
    "#                 y_batch.append([ i[0] for i in base_predictions_on[:] ])\n",
    "            \n",
    "#             elif self.hyper_params['loss_type'] == 'postfix':\n",
    "#                 x_batch.append([ i[0] for i in base_predictions_on[:] ])\n",
    "#                 y_batch_s[now_at, :].scatter_(\n",
    "#                     0, LongTensor([ i[0] for i in base_predictions_on[:] ]), 1.0\n",
    "#                 )\n",
    "#                 y_batch.append([ i[0] for i in base_predictions_on[:] ])\n",
    "                \n",
    "#             elif self.hyper_params['loss_type'] == 'exp_decay':\n",
    "#                 x_batch.append([ i[0] for i in base_predictions_on[:] ])\n",
    "#                 y_batch_s[now_at, :].scatter_(\n",
    "#                     # 0, LongTensor([ i[0] for i in base_predictions_on[:] ]), FloatTensor([ np.e ** (-1.0 * i) for i in range(len(base_predictions_on[:])) ]), \n",
    "#                     0, LongTensor([ i[0] for i in base_predictions_on[:] ]), FloatTensor([ 1.0 / (i + 1.0) for i in range(len(base_predictions_on[:])) ]), \n",
    "#                     # 0, LongTensor([ i[0] for i in base_predictions_on[:] ]), FloatTensor([ 1.0 / np.log2(i + 2.0) for i in range(len(base_predictions_on[:])) ]), \n",
    "#                 )\n",
    "#                 y_batch.append([ i[0] for i in base_predictions_on[:-1] ])\n",
    "            \n",
    "            now_at += 1\n",
    "            \n",
    "            test_movies.append([ i[0] for i in heldout_movies ])\n",
    "            test_movies_r.append([ i[1] for i in heldout_movies ])\n",
    "            \n",
    "            if now_at == self.batch_size:\n",
    "                \n",
    "                yield Variable(LongTensor(x_batch)), Variable(y_batch_s, requires_grad=False), \\\n",
    "                test_movies, test_movies_r\n",
    "                \n",
    "                x_batch = []\n",
    "                y_batch_s = torch.zeros(self.batch_size, self.num_items).cuda()\n",
    "                y_batch = []\n",
    "                test_movies, test_movies_r = [], []\n",
    "                now_at = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, reader, hyper_params, is_train_set):\n",
    "    model.eval()\n",
    "\n",
    "    metrics = {}\n",
    "    metrics['loss'] = 0.0\n",
    "    Ks = [10, 100]\n",
    "    for k in Ks: \n",
    "        metrics['NDCG@' + str(k)] = 0.0\n",
    "        metrics['HR@' + str(k)] = 0.0\n",
    "        metrics['Prec@' + str(k)] = 0.0\n",
    "\n",
    "    batch = 0\n",
    "    total_ndcg = 0.0\n",
    "    \n",
    "    len_to_ndcg_at_100_map = {}\n",
    "\n",
    "    for x, y_s, test_movies, test_movies_r in reader.iter_eval():\n",
    "        batch += 1\n",
    "        if is_train_set == True and batch > hyper_params['train_cp_users']: break\n",
    "\n",
    "        decoder_output, z_mean, z_log_sigma = model(x)\n",
    "        \n",
    "        metrics['loss'] += criterion(decoder_output, z_mean, z_log_sigma, y_s, 0.2).data[0]\n",
    "        \n",
    "        # decoder_output[X.nonzero()] = -np.inf\n",
    "        decoder_output = decoder_output.data\n",
    "        \n",
    "        x_scattered = torch.zeros(decoder_output.shape[0], decoder_output.shape[2]).cuda()\n",
    "        x_scattered[0, :].scatter_(0, x[0].data, 1.0)\n",
    "        \n",
    "        # If loss type is predict next, the last element in the train sequence is not included in x\n",
    "        #### Should ideally be done, but it's alright :)\n",
    "        # if hyper_params['loss_type'] == 'predict_next': x_scattered[0, y[0][-1]] = 1.0\n",
    "        \n",
    "        last_predictions = decoder_output[:, -1, :] - \\\n",
    "        (torch.abs(decoder_output[:, -1, :] * x_scattered) * 100000000)\n",
    "        \n",
    "        for batch_num in range(last_predictions.shape[0]):\n",
    "            predicted_scores = last_predictions[batch_num]\n",
    "            actual_movies_watched = test_movies[batch_num]\n",
    "            actual_movies_ratings = test_movies_r[batch_num]\n",
    "                    \n",
    "            # Calculate NDCG\n",
    "            _, argsorted = torch.sort(-1.0 * predicted_scores)\n",
    "            for k in Ks:\n",
    "                best = 0.0\n",
    "                now_at = 0.0\n",
    "                dcg = 0.0\n",
    "                hr = 0.0\n",
    "                \n",
    "                rec_list = list(argsorted[:k].cpu().numpy())\n",
    "                for m in range(len(actual_movies_watched)):\n",
    "                    movie = actual_movies_watched[m]\n",
    "                    now_at += 1.0\n",
    "                    if now_at <= k: best += 1.0 / float(np.log2(now_at + 1))\n",
    "                    \n",
    "                    if movie not in rec_list: continue\n",
    "                    hr += 1.0\n",
    "                    dcg += 1.0 / float(np.log2(float(rec_list.index(movie) + 2)))\n",
    "                \n",
    "                metrics['NDCG@' + str(k)] += float(dcg) / float(best)\n",
    "                metrics['HR@' + str(k)] += float(hr) / float(len(actual_movies_watched))\n",
    "                metrics['Prec@' + str(k)] += float(hr) / float(k)\n",
    "                \n",
    "                if k == 100:\n",
    "                    seq_len = int(len(actual_movies_watched)) + int(x[batch_num].shape[0]) + 1\n",
    "                    if seq_len not in len_to_ndcg_at_100_map: len_to_ndcg_at_100_map[seq_len] = []\n",
    "                    len_to_ndcg_at_100_map[seq_len].append(float(dcg) / float(best))\n",
    "                \n",
    "            total_ndcg += 1.0\n",
    "    \n",
    "    metrics['loss'] = float(metrics['loss']) / float(batch)\n",
    "    metrics['loss'] = round(metrics['loss'], 4)\n",
    "    \n",
    "    for k in Ks:\n",
    "        metrics['NDCG@' + str(k)] = round((100.0 * metrics['NDCG@' + str(k)]) / float(total_ndcg), 4)\n",
    "        metrics['HR@' + str(k)] = round((100.0 * metrics['HR@' + str(k)]) / float(total_ndcg), 4)\n",
    "        metrics['Prec@' + str(k)] = round((100.0 * metrics['Prec@' + str(k)]) / float(total_ndcg), 4)\n",
    "        \n",
    "    return metrics, len_to_ndcg_at_100_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hyper_params):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(\n",
    "            hyper_params['rnn_size'], hyper_params['hidden_size']\n",
    "        )\n",
    "        nn.init.xavier_normal(self.linear1.weight)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hyper_params):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(hyper_params['latent_size'], hyper_params['hidden_size'])\n",
    "        self.linear2 = nn.Linear(hyper_params['hidden_size'], hyper_params['total_items'])\n",
    "        nn.init.xavier_normal(self.linear1.weight)\n",
    "        nn.init.xavier_normal(self.linear2.weight)\n",
    "        self.activation = nn.Tanh()\n",
    "        # self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        # x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(features))\n",
    "        self.beta = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, hyper_params):\n",
    "        super(Model, self).__init__()\n",
    "        self.hyper_params = hyper_params\n",
    "        \n",
    "        self.encoder = Encoder(hyper_params)\n",
    "        self.decoder = Decoder(hyper_params)\n",
    "        \n",
    "        # No +1 means can never pad, hence bsz has to be equal 1\n",
    "        self.item_embed = nn.Embedding(hyper_params['total_items'], hyper_params['item_embed_size'])\n",
    "        \n",
    "        self.gru = nn.GRU(\n",
    "            hyper_params['item_embed_size'], hyper_params['rnn_size'], \n",
    "            batch_first=True, num_layers=1\n",
    "        )\n",
    "        \n",
    "        self.layer_temp = nn.Linear(hyper_params['hidden_size'], 2 * hyper_params['latent_size'])\n",
    "        nn.init.xavier_normal(self.layer_temp.weight)\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def sample_latent(self, h_enc):\n",
    "        \"\"\"\n",
    "        Return the latent normal sample z ~ N(mu, sigma^2)\n",
    "        \"\"\"\n",
    "        temp_out = self.layer_temp(h_enc)\n",
    "        \n",
    "        mu = temp_out[:, :self.hyper_params['latent_size']]\n",
    "        log_sigma = temp_out[:, self.hyper_params['latent_size']:]\n",
    "        \n",
    "        sigma = torch.exp(log_sigma)\n",
    "        std_z = torch.from_numpy(np.random.normal(0, 1, size=sigma.size())).float()\n",
    "        if is_cuda_available: std_z = std_z.cuda()\n",
    "\n",
    "        self.z_mean = mu\n",
    "        self.z_log_sigma = log_sigma\n",
    "\n",
    "        return mu + sigma * Variable(std_z, requires_grad=False)  # Reparameterization trick\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_shape = x.shape\n",
    "        x = x.view(-1)\n",
    "        \n",
    "        x = self.item_embed(x)\n",
    "        x = x.view(in_shape[0], in_shape[1], -1)\n",
    "        \n",
    "        rnn_out, _ = self.gru(x)\n",
    "        rnn_out = rnn_out.view(in_shape[0] * in_shape[1], -1)\n",
    "        \n",
    "        enc_out = self.encoder(rnn_out)\n",
    "        sampled_z = self.sample_latent(enc_out)\n",
    "        \n",
    "#         if self.hyper_params['conditional'] == True:\n",
    "#             mult_matrix = torch.zeros(in_shape[0], in_shape[1], in_shape[1]).cuda()\n",
    "#             for b in range(in_shape[0]):\n",
    "#                 for i in range(in_shape[1]):\n",
    "#                     num_one = i + 1 - max(i-self.hyper_params['attention_context']+1, 0)\n",
    "#                     to_put = 1.0 / float(num_one)\n",
    "#                     for j in range(max(i-self.hyper_params['attention_context']+1, 0), i+1): mult_matrix[b, i, j] = to_put\n",
    "#             mult_matrix = Variable(mult_matrix.view(in_shape[0]*in_shape[1], in_shape[1]))\n",
    "            \n",
    "#             print(mult_matrix.shape)\n",
    "#             print(sampled_z.shape)\n",
    "#             sampled_z = torch.mm(mult_matrix, sampled_z)\n",
    "        \n",
    "        dec_out = self.decoder(sampled_z)\n",
    "        dec_out = dec_out.view(in_shape[0], in_shape[1], -1)\n",
    "                              \n",
    "        return dec_out, self.z_mean, self.z_log_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class VAELoss(torch.nn.Module):\n",
    "    def __init__(self, hyper_params):\n",
    "        super(VAELoss,self).__init__()\n",
    "        self.hyper_params = hyper_params\n",
    "\n",
    "    def forward(self, decoder_output, mu_q, logvar_q, y_true_s, anneal):\n",
    "        # Calculate KL Divergence loss\n",
    "        kld = torch.mean(torch.sum(0.5 * (-logvar_q + torch.exp(logvar_q) + mu_q**2 - 1), -1))\n",
    "    \n",
    "        # decoder_output shape : [batch_size, seq_len, all_items]\n",
    "        dec_shape = decoder_output.shape\n",
    "\n",
    "        decoder_output = F.log_softmax(decoder_output, -1)\n",
    "        num_ones = float(torch.sum(y_true_s[0, 0]))\n",
    "        \n",
    "        likelihood = torch.sum(\n",
    "            -1.0 * y_true_s.view(dec_shape[0] * dec_shape[1], -1) * \\\n",
    "            decoder_output.view(dec_shape[0] * dec_shape[1], -1)\n",
    "        ) / (float(self.hyper_params['batch_size']) * num_ones)\n",
    "        \n",
    "        final = (anneal * kld) + (1.0 * likelihood)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started reading data file\n",
      "Data Files loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 435180/435180 [00:00<00:00, 642373.24it/s]\n",
      "100%|██████████| 54859/54859 [00:00<00:00, 954807.84it/s]\n",
      "100%|██████████| 14097/14097 [00:00<00:00, 176110.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Simulation run on: 2018-10-18 13:58:01.508097\n",
      "\n",
      "\n",
      "Data reading complete!\n",
      "Number of train batches: 4534\n",
      "Number of test batches:  750\n",
      "Total Items: 3483\n",
      "\n",
      "Model(\n",
      "  (encoder): Encoder(\n",
      "    (linear1): Linear(in_features=200, out_features=150, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (linear1): Linear(in_features=64, out_features=150, bias=True)\n",
      "    (linear2): Linear(in_features=150, out_features=3483, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (item_embed): Embedding(3483, 256)\n",
      "  (gru): GRU(256, 200, batch_first=True)\n",
      "  (layer_temp): Linear(in_features=150, out_features=128, bias=True)\n",
      "  (tanh): Tanh()\n",
      ")\n",
      "\n",
      "Model Built!\n",
      "Starting Training...\n",
      "\n",
      "| epoch   1 |  1000/ 4534 batches | ms/batch 11.61 | loss 644.7640\n",
      "| epoch   1 |  2000/ 4534 batches | ms/batch 13.41 | loss 624.2364\n",
      "| epoch   1 |  3000/ 4534 batches | ms/batch 12.22 | loss 592.6732\n",
      "| epoch   1 |  4000/ 4534 batches | ms/batch 13.24 | loss 642.5493\n",
      "| epoch   1 |  4534/ 4534 batches | ms/batch 11.95 | loss 565.5067\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 62.92s | loss = 418.4729 | NDCG@10 = 14.2315 | HR@10 = 9.6945 | Prec@10 = 12.4 | NDCG@100 = 25.4485 | HR@100 = 43.1925 | Prec@100 = 6.045 (TRAIN)\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 62.92s | loss = 446.636 | NDCG@10 = 14.9784 | HR@10 = 10.6629 | Prec@10 = 12.2933 | NDCG@100 = 26.1367 | HR@100 = 44.314 | Prec@100 = 6.0707 (TEST)\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |  1000/ 4534 batches | ms/batch 12.08 | loss 555.4707\n",
      "| epoch   2 |  2000/ 4534 batches | ms/batch 12.69 | loss 576.4306\n",
      "| epoch   2 |  3000/ 4534 batches | ms/batch 12.36 | loss 563.5723\n",
      "| epoch   2 |  4000/ 4534 batches | ms/batch 13.48 | loss 617.3925\n",
      "| epoch   2 |  4534/ 4534 batches | ms/batch 12.20 | loss 547.1486\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 63.18s | loss = 406.6872 | NDCG@10 = 17.7126 | HR@10 = 12.4428 | Prec@10 = 14.7 | NDCG@100 = 28.5497 | HR@100 = 46.5204 | Prec@100 = 6.52 (TRAIN)\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 63.18s | loss = 436.1387 | NDCG@10 = 16.5321 | HR@10 = 12.0397 | Prec@10 = 13.5733 | NDCG@100 = 28.1801 | HR@100 = 47.0699 | Prec@100 = 6.5187 (TEST)\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |  1000/ 4534 batches | ms/batch 11.88 | loss 539.2305\n",
      "| epoch   3 |  2000/ 4534 batches | ms/batch 12.44 | loss 562.0286\n",
      "| epoch   3 |  3000/ 4534 batches | ms/batch 12.14 | loss 551.8971\n",
      "| epoch   3 |  4000/ 4534 batches | ms/batch 13.25 | loss 605.5689\n",
      "| epoch   3 |  4534/ 4534 batches | ms/batch 11.99 | loss 537.9435\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 62.18s | loss = 400.8508 | NDCG@10 = 18.779 | HR@10 = 12.9029 | Prec@10 = 15.05 | NDCG@100 = 29.8175 | HR@100 = 47.5523 | Prec@100 = 6.72 (TRAIN)\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 62.18s | loss = 432.038 | NDCG@10 = 16.7318 | HR@10 = 12.3816 | Prec@10 = 13.8267 | NDCG@100 = 28.7468 | HR@100 = 48.1475 | Prec@100 = 6.7187 (TEST)\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |  1000/ 4534 batches | ms/batch 13.05 | loss 530.5877\n",
      "| epoch   4 |  2000/ 4534 batches | ms/batch 12.89 | loss 553.8291\n",
      "| epoch   4 |  3000/ 4534 batches | ms/batch 12.13 | loss 544.8844\n",
      "| epoch   4 |  4000/ 4534 batches | ms/batch 13.33 | loss 598.2054\n",
      "| epoch   4 |  4534/ 4534 batches | ms/batch 11.97 | loss 532.2640\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 63.86s | loss = 397.5503 | NDCG@10 = 18.4337 | HR@10 = 12.9454 | Prec@10 = 15.25 | NDCG@100 = 30.1113 | HR@100 = 49.8767 | Prec@100 = 6.93 (TRAIN)\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 63.86s | loss = 429.8841 | NDCG@10 = 16.7279 | HR@10 = 12.3204 | Prec@10 = 13.9333 | NDCG@100 = 28.9852 | HR@100 = 48.6837 | Prec@100 = 6.7547 (TEST)\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |  1000/ 4534 batches | ms/batch 11.87 | loss 524.9986\n",
      "| epoch   5 |  2000/ 4534 batches | ms/batch 12.43 | loss 548.2715\n",
      "| epoch   5 |  3000/ 4534 batches | ms/batch 12.17 | loss 540.1431\n",
      "| epoch   5 |  4000/ 4534 batches | ms/batch 13.25 | loss 593.2426\n",
      "| epoch   5 |  4534/ 4534 batches | ms/batch 12.01 | loss 528.1866\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 62.19s | loss = 395.6601 | NDCG@10 = 18.8057 | HR@10 = 12.8672 | Prec@10 = 15.2 | NDCG@100 = 30.738 | HR@100 = 50.6878 | Prec@100 = 7.0 (TRAIN)\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 62.19s | loss = 429.34 | NDCG@10 = 17.0139 | HR@10 = 12.7364 | Prec@10 = 14.12 | NDCG@100 = 29.2418 | HR@100 = 48.9857 | Prec@100 = 6.816 (TEST)\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |  1000/ 4534 batches | ms/batch 11.89 | loss 521.0017\n",
      "| epoch   6 |  2000/ 4534 batches | ms/batch 12.44 | loss 544.1264\n",
      "| epoch   6 |  3000/ 4534 batches | ms/batch 12.13 | loss 536.5053\n",
      "| epoch   6 |  4000/ 4534 batches | ms/batch 13.21 | loss 589.3715\n",
      "| epoch   6 |  4534/ 4534 batches | ms/batch 11.97 | loss 525.0108\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 62.13s | loss = 394.2799 | NDCG@10 = 19.1392 | HR@10 = 13.1994 | Prec@10 = 15.4 | NDCG@100 = 31.2267 | HR@100 = 50.831 | Prec@100 = 7.05 (TRAIN)\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 62.13s | loss = 429.253 | NDCG@10 = 17.3071 | HR@10 = 12.9223 | Prec@10 = 14.4133 | NDCG@100 = 29.2843 | HR@100 = 48.8009 | Prec@100 = 6.8267 (TEST)\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |  1000/ 4534 batches | ms/batch 12.09 | loss 517.8420\n",
      "| epoch   7 |  2000/ 4534 batches | ms/batch 12.69 | loss 540.7328\n",
      "| epoch   7 |  3000/ 4534 batches | ms/batch 12.37 | loss 533.6107\n",
      "| epoch   7 |  4000/ 4534 batches | ms/batch 13.46 | loss 586.2618\n",
      "| epoch   7 |  4534/ 4534 batches | ms/batch 12.18 | loss 522.2402\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 63.18s | loss = 393.3955 | NDCG@10 = 19.1727 | HR@10 = 13.4159 | Prec@10 = 15.75 | NDCG@100 = 31.2431 | HR@100 = 51.1792 | Prec@100 = 7.16 (TRAIN)\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 63.18s | loss = 429.5613 | NDCG@10 = 17.1494 | HR@10 = 12.6503 | Prec@10 = 14.2533 | NDCG@100 = 29.2702 | HR@100 = 48.6038 | Prec@100 = 6.8187 (TEST)\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |  1000/ 4534 batches | ms/batch 11.91 | loss 515.2227\n",
      "| epoch   8 |  2000/ 4534 batches | ms/batch 12.46 | loss 537.9287\n",
      "| epoch   8 |  3000/ 4534 batches | ms/batch 12.14 | loss 531.1299\n",
      "| epoch   8 |  4000/ 4534 batches | ms/batch 13.21 | loss 583.6491\n",
      "| epoch   8 |  4534/ 4534 batches | ms/batch 11.99 | loss 519.8719\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 62.18s | loss = 392.6234 | NDCG@10 = 19.1019 | HR@10 = 12.8178 | Prec@10 = 15.35 | NDCG@100 = 31.5299 | HR@100 = 51.553 | Prec@100 = 7.17 (TRAIN)\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 62.18s | loss = 430.0926 | NDCG@10 = 16.9214 | HR@10 = 12.4574 | Prec@10 = 14.08 | NDCG@100 = 29.1082 | HR@100 = 48.6746 | Prec@100 = 6.7947 (TEST)\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting from training early\n",
      "=========================================================================================\n",
      "| End of training | loss = 429.2771 | NDCG@10 = 17.1222 | HR@10 = 12.94 | Prec@10 = 14.28 | NDCG@100 = 29.1617 | HR@100 = 48.6428 | Prec@100 = 6.8133\n",
      "=========================================================================================\n",
      "[5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 129, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 146, 147, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 172, 173, 175, 177, 179, 180, 181, 182, 183, 184, 185, 187, 188, 190, 191, 192, 193, 194, 195, 197, 200, 202, 204, 206, 207, 212, 213, 214, 215, 216, 218, 219, 221, 223, 224, 225, 226, 227, 231, 232, 234, 235, 237, 238, 239, 244, 245, 248, 249, 250, 253, 255, 257, 261, 268, 270, 272, 274, 283, 284, 285, 286, 293, 296, 297, 305, 311, 314, 320, 324, 327, 336, 337, 341, 345, 350, 356, 380, 406, 407, 418, 431, 439, 441, 463, 482, 492, 514, 544, 562, 563, 604, 632, 815]\n",
      "[0.0, 9.054480964374868, 9.12613716404963, 6.844602873037223, 13.838030666335749, 17.52474843804557, 21.34779725765615, 25.157327554202084, 28.24662124342826, 24.175111971189246, 26.835473802911633, 24.613695996438757, 25.88552922912815, 28.01446985519174, 28.9867947686501, 29.187445112105667, 29.54149447230173, 29.656927145551965, 29.3564226395231, 28.8363497001528, 31.27367864834067, 32.556531488135995, 32.00717573743884, 31.386882110320954, 33.27014537495149, 32.349216343085935, 35.6302981512157, 34.09881037511883, 37.5783778453954, 35.80898504028008, 36.824872262712574, 31.41515190731271, 28.428097788380228, 27.171301337207762, 29.634321744979417, 29.266736876593615, 29.419749507061773, 39.63841834620378, 39.05384883662245, 39.689768772930044, 38.9804001613399, 40.85637575467205, 38.27657693893985, 37.43275819947088, 35.542337348371134, 33.133159757872576, 35.69795680287066, 34.09578076735026, 38.67680619433497, 39.6222835578332, 39.67363864070102, 34.09292562224393, 29.643515702494746, 24.490082267911074, 20.984334531695357, 20.022287177458395, 22.434519503551844, 25.899896514683196, 27.497765162066646, 28.477240049692114, 30.723517627128366, 31.636413562711162, 31.53757901966275, 34.24025666333171, 34.907918905307014, 36.74072227716552, 38.04964456089878, 32.44201921766765, 29.707998781688055, 30.304362356473177, 29.23361742103417, 23.68048151259441, 28.43481216131415, 27.955929747350286, 33.121335502882836, 31.075935077168833, 32.5995082085698, 29.94044107915368, 31.27571595915932, 32.67811004418534, 30.124745587852907, 28.747915159813452, 31.459879272403033, 28.805085452625327, 21.491796435771107, 21.18797390249481, 22.20218604383884, 19.808760014830657, 19.78391668327465, 20.204713569867558, 21.937190272128444, 26.313145005443637, 28.722616309643495, 32.5590920889548, 32.27197415574259, 32.74729304702538, 25.910811143910326, 26.062978538978086, 23.405615553569607, 23.313064191875952, 23.243907149703027, 32.131529153765555, 27.90927567822456, 32.21861638593255, 32.349923901855206, 36.423260882118946, 34.70670326177181, 41.067860351027946, 36.310724330504414, 37.15367664585271, 35.373421177657356, 34.41911787995711, 33.32369869174279, 29.145256196334337, 27.737113657274552, 26.545940051881377, 23.2805215752405, 20.993284139877197, 25.07143429725904, 28.489960093262177, 27.540618740567208, 25.725012315221687, 28.755325659238064, 28.43107534595641, 24.798716000574608, 21.775715817568592, 29.43213383889676, 28.4333322820061, 27.632822881721474, 27.89558045072951, 29.320706918664722, 25.518142343843852, 21.750066667566397, 26.424906584141148, 22.445096415645967, 27.643173329925087, 27.019068255906483, 32.66497458088469, 25.563862301282747, 32.73717194336892, 35.583562516382564, 36.07662180048832, 42.25652247239269, 45.36636841570462, 42.154448567449926, 32.444608609759136, 35.6370381134508, 24.863298562390614, 25.631678455560536, 24.24416414916327, 24.6358849282508, 23.70486753536681, 27.613794901969015, 28.77768505861776, 27.342512373963455, 32.28311737935134, 25.563901316377148, 18.539307637920174, 18.546120911295013, 20.62201490310361, 18.457497705681664, 22.734098346093, 24.304916775462623, 18.795879935287594, 18.756941198918845, 18.984221492753747, 16.138872292718723, 21.14623572027607, 24.259693123028537, 29.407459109381215, 28.17896644701043, 27.698003102932432, 21.573548789220773, 20.737158649692923, 18.42725998977132, 20.637518183792213, 22.34193144426056, 30.382721427395882, 27.751676577444833, 22.749755224883106, 19.785032852831478, 22.334624912737542, 20.49582143342075, 21.165009101673814, 24.55936794071505, 25.176901039017842, 23.17856847372145, 18.6211466551675, 19.392892146305876, 20.426427076849393, 20.080503369054018, 17.211272092798534, 17.924703394651097, 26.490061572999508, 26.63116520763834, 23.389948233162585, 24.769854631063446, 27.596531826090008, 22.556348658081856, 19.534767870442927, 21.157275552598854, 26.009978739471183, 20.982264362624885, 15.755441300792693, 16.576397964146572, 19.96816183077979, 14.176923037897376, 14.494162952287473, 20.039856312509393, 19.499070340714475, 18.41248597900212, 24.723693334336104, 26.36621597033161, 24.835860704724077, 26.426951064725635, 25.39161263780358, 21.149245413373205, 21.117400734591477, 18.947434121620336, 20.766062380073766, 21.229249209938597, 20.166443040417967, 22.465829998326363, 25.384923303192448, 19.794891273246765, 21.68523956101103, 29.90531277538227, 27.640640647040055, 26.81494656681687, 31.221385265668648, 33.535207904505114, 27.468058193462195, 26.74000159289063, 26.637098865706747, 24.94350407578086, 18.804467428380796, 15.889782966865363, 15.278417545373406, 16.001902290274952, 17.306561614120334, 19.170373350707983, 19.910825272632714]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'saved_plots/seq_len_vs_ndcg_ml.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8c7258a110ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;31m# Plot sequence length vs NDCG@100 graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m \u001b[0mplot_len_vs_ndcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_to_ndcg_at_100_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;31m# Plot Traning graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-8c7258a110ed>\u001b[0m in \u001b[0;36mplot_len_vs_ndcg\u001b[0;34m(len_to_ndcg_at_100_map)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Average NDCG@100\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Movielens\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved_plots/seq_len_vs_ndcg_ml.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;31m#plt.xscale('log', basex=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m#axes = plt.gca()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/noveen/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/noveen/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, **kwargs)\u001b[0m\n\u001b[1;32m   2033\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_frameon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2035\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2037\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/noveen/anaconda3/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2261\u001b[0m                 \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2262\u001b[0m                 \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2263\u001b[0;31m                 **kwargs)\n\u001b[0m\u001b[1;32m   2264\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/noveen/anaconda3/lib/python3.6/site-packages/matplotlib/backends/backend_pdf.py\u001b[0m in \u001b[0;36mprint_pdf\u001b[0;34m(self, filename, **kwargs)\u001b[0m\n\u001b[1;32m   2576\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2577\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2578\u001b[0;31m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPdfFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2579\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m             \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/noveen/anaconda3/lib/python3.6/site-packages/matplotlib/backends/backend_pdf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, metadata)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_file_like\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_filehandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_opened\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/noveen/anaconda3/lib/python3.6/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m         \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seek'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saved_plots/seq_len_vs_ndcg_ml.pdf'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train(reader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    batch = 0\n",
    "    batch_limit = int(train_reader.num_b)\n",
    "    total_anneal_steps = 200000\n",
    "    anneal = 0.0\n",
    "    update_count = 0.0\n",
    "    anneal_cap = 0.2\n",
    "\n",
    "    for x, y_s in reader.iter():\n",
    "        # print(x[0])\n",
    "        batch += 1\n",
    "        \n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        decoder_output, z_mean, z_log_sigma = model(x)\n",
    "        \n",
    "        loss = criterion(decoder_output, z_mean, z_log_sigma, y_s, anneal)\n",
    "        loss.backward()\n",
    "        \n",
    "        # nn.utils.clip_grad_norm(model.parameters(), hyper_params['exploding_clip'])\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.data\n",
    "        \n",
    "        if total_anneal_steps > 0:\n",
    "            anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
    "        else:\n",
    "            anneal = anneal_cap\n",
    "        update_count += 1.0\n",
    "\n",
    "        if (batch % hyper_params['batch_log_interval'] == 0 and batch > 0) or batch == batch_limit:\n",
    "            div = hyper_params['batch_log_interval']\n",
    "            if batch == batch_limit: div = (batch_limit % hyper_params['batch_log_interval']) - 1\n",
    "            if div <= 0: div = 1\n",
    "\n",
    "            cur_loss = (total_loss[0] / div)\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            ss = '| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | loss {:5.4f}'.format(\n",
    "                    epoch, batch, batch_limit, (elapsed * 1000) / div, cur_loss\n",
    "            )\n",
    "            \n",
    "            file_write(hyper_params['log_file'], ss)\n",
    "\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "            \n",
    "def plot_len_vs_ndcg(len_to_ndcg_at_100_map):\n",
    "    \n",
    "    X_mvae_netflix = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 189, 191, 192, 194, 195, 196, 197, 198, 199, 200]\n",
    "    Y_mvae_netflix = [17.305459805165263, 18.271700778729297, 19.939235397849227, 20.615807779071446, 21.200536304667036, 22.668206604989916, 23.62762111889102, 24.1113769160321, 24.38576784295414, 24.651906312317955, 24.572177126181142, 24.097612237466684, 23.361091530883265, 22.961639225853908, 22.380616601147683, 22.570365422661485, 23.226473729740466, 23.55808194301172, 23.905232990628896, 24.67609924695598, 24.790753393108893, 24.699341448600368, 24.329625071791032, 24.34869768801409, 24.255240658584107, 23.8571758262351, 23.59269525353753, 23.732532176874358, 24.30481045301082, 23.70875891299226, 23.81468415071772, 23.64207029682717, 24.173490233620566, 23.01290689462342, 23.44197538425504, 23.115913341499848, 23.312578258072, 22.424685145841657, 23.41878275174073, 22.859779958188703, 23.478619357990972, 23.722274237306653, 24.111670143968666, 23.103060793686897, 23.261865738449355, 22.530793995200533, 22.46222150614473, 22.412599304559407, 22.414945145593123, 22.31086851922349, 22.17761897571351, 21.88076868966187, 21.768170856351094, 22.028155064021156, 21.71684577025067, 21.22732928030378, 20.609413899994195, 19.800055402123387, 19.381503434943006, 19.603972896073685, 19.862933729279177, 19.799475300978543, 19.843200740090065, 19.8870036930784, 19.477139969242245, 19.4631147662293, 19.728978375382674, 20.224790558321782, 19.94221122018891, 20.21560702269877, 19.66444342853739, 19.676951322853924, 20.232758626818303, 20.184517727868005, 19.51926377235292, 19.835604528281827, 20.13285325658148, 19.852840347617573, 19.557859649630423, 19.732197250399338, 20.036022080266843, 18.835314931400724, 19.317207401473976, 19.647503418236795, 19.658537264648448, 18.29569173398534, 18.696987223207543, 17.679959148502046, 17.47765647083317, 17.084835433149657, 17.4203317776519, 17.83049612504641, 17.154211742812475, 16.502866586006053, 17.147364004991793, 16.752288905284654, 15.554803397344633, 15.490649701740205, 15.365954299879494, 15.234798613879189, 16.116028759933034, 16.777042712910383, 17.474257186260022, 18.662170625953102, 18.25708466548021, 18.044341072937918, 17.732739778385657, 17.70456456016834, 16.5946121967739, 16.643935340980068, 16.03153896942279, 16.17903722214664, 15.48849466167474, 16.334893836091368, 15.980542629478663, 16.223256166311366, 16.99047381857931, 18.494408413854845, 19.07966764732772, 18.69168202040712, 19.56019857225473, 19.55335660690402, 18.942472171512193, 17.848991098200255, 19.33229713629901, 19.644705606240155, 19.58588755723168, 20.371979264473254, 20.969026944425785, 19.618733831284523, 18.939347373823544, 18.2926115801619, 17.905964313216998, 17.513850083910732, 18.954914320807354, 19.516843305093158, 19.16239432825069, 18.04474632050065, 18.471264893817626, 17.280071669030267, 17.779933740252858, 18.17361340040471, 19.33458238658996, 19.704600520321375, 20.796094783953684, 20.32572057556, 21.25600269355972, 20.451352094565802, 20.46366934934908, 18.66755377700566, 17.285141822485848, 17.008886326565896, 17.116426241913263, 17.17191393661636, 17.740607538964838, 18.31040755631411, 16.941964737975486, 17.255713721885556, 15.545303497687973, 15.032243814270108, 15.67488045996087, 15.75790529362007, 15.821777605379534, 16.51116636728033, 17.8806208772918, 18.55545955039922, 20.051227883380886, 20.478703679872652, 20.60864595614596, 21.17214481181908, 19.670823745486132, 20.093266457401263, 17.656685144370634, 19.484065103835995, 19.01808282525615, 18.803368344628062, 19.347414884808465, 21.33056403749105, 19.916156599030852, 20.305107750441515, 21.87774985484024, 19.306331918087075, 19.73467045052776, 21.06087808019119, 20.203695908837613, 20.374355222523583, 23.96444695089085, 22.23914388628821, 19.475972613773443, 17.480550314956872, 16.66621357973195, 14.26344037396423, 14.024447491048988, 15.53859478055956, 19.81240003959899, 17.975738014329544, 19.355593730440038]\n",
    "\n",
    "    #X_caser_netflix = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 76, 78, 79, 82, 83, 84, 87, 88, 89, 93, 97, 99, 102, 103, 109, 110, 113, 121, 127, 136, 152, 160, 163]\n",
    "    #Y_caser_netflix = [16.485085672216037, 18.747429945674003, 20.70896325823069, 22.274748734876773, 23.958296584266115, 26.55151746407545, 29.031670288905907, 30.299196231145896, 31.853266701606675, 32.368682209107874, 34.47022374355164, 31.586889875434753, 31.312491843238597, 29.68294276103537, 28.738119281356415, 26.783961566150033, 28.240157730515865, 28.081689400389923, 27.02566266144924, 26.864874439062373, 26.491010579644854, 27.09857589397714, 26.19853959140324, 27.01040859620567, 26.466000049491253, 24.743734902944883, 23.97695258723686, 23.796191184057946, 24.092584600277316, 23.30043531446083, 25.78689753003254, 26.85863210242469, 27.87029236537054, 27.4475221523274, 26.869912639341567, 26.297849906130665, 23.302306922109842, 21.775402832671514, 20.068269790515046, 21.185051385338472, 20.967370945317732, 20.98113222440973, 21.307069353022985, 21.599862392432176, 20.42497393290995, 18.795313318889207, 19.740882624603966, 20.57957208190134, 24.21087122007957, 23.501963985112432, 24.89061382552697, 22.842888656903167, 23.72005618702017, 17.62799016897126, 19.85917928876337, 19.64989000883951, 24.727002309823725, 21.87704201967477, 24.724995559321986, 26.368554354877375, 25.783655106475372, 23.354241485490224, 22.33465457893313, 20.327298031223584, 15.1265894762262, 16.06087006844015, 16.11003479892775, 19.48637251559304, 22.620831283556992, 22.289844898040194, 20.747426916367914, 19.251491528058374, 17.494689186306818, 17.279438001137468, 18.88280796886336, 19.40042651825565, 23.031706931139745, 23.669073803533642, 23.18997694201091, 23.744868407686305, 24.122741837443613, 21.667662813739867, 18.900717516150163, 15.77712867987563, 17.92647075389864, 16.93509903749765, 16.651559515501425, 20.77953950073382, 21.493690688749748, 17.479524350881874, 22.400733446255664, 27.065161696330712, 25.216483919020387]\n",
    "    \n",
    "    X_mvae_ml1m = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 57, 58, 60, 61, 63, 64, 66, 69, 70, 82, 84, 87, 89, 93, 99, 103, 113, 127, 163]\n",
    "    Y_mvae_ml1m = [17.458343004804494, 25.68476725993679, 25.720223215791837, 25.597031830677235, 25.60894056452916, 27.212572655779933, 25.64280500408476, 26.946060711011416, 26.63155525896347, 26.570093706839668, 26.25265966672373, 26.24333246048654, 25.53109395164712, 25.196273849545193, 24.887480921672573, 24.18543800818245, 22.92177142891318, 20.19508267535594, 19.332850481686087, 18.517308642420755, 18.342761260362618, 17.728572394294858, 18.537252938520773, 18.833241815050933, 19.17857499436072, 17.889340756422133, 18.65369315804576, 20.091951078456706, 20.75806352196072, 22.47769631516441, 22.675843256048417, 21.77756921701781, 20.79989233259795, 20.63145877709492, 18.5998405400912, 18.082530407190426, 17.894127770884484, 15.353203887559113, 15.952639014230744, 15.252710639204718, 16.385665444911506, 13.741593127699593, 15.00266567689466, 16.058235079070204, 19.37848315523579, 18.86218161381533, 22.846203388265362, 23.962431804326116, 22.00613586999038, 21.265969002801462, 22.787056310591787, 21.015072022172696, 20.750919652745413, 21.33487821640185, 22.696750014491947, 23.157508889235253, 23.489746031457884, 23.8165395345481, 21.325967130172135, 15.702065969721346, 13.880828878658292, 11.60894842735441, 10.700079545157555, 12.676074201036371, 14.020292706307837, 16.627015897770967, 21.424928736322777, 22.043991130616757, 21.148713304006623, 20.69858947097228, 16.900969363977584, 11.989916720631882]\n",
    "    \n",
    "    X_caser_ml1m = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 76, 78, 79, 82, 83, 84, 87, 88, 89, 93, 97, 99, 102, 103, 109, 110, 113, 121, 127, 136, 152, 160, 163]\n",
    "    Y_caser_ml1m = [0.0, 10.028344645594448, 14.675889953551462, 17.470951011175373, 20.028055079279955, 26.048766562683625, 28.985644886068997, 30.136517017997345, 31.869327633606026, 32.22796180526963, 34.40297811810012, 31.57751429369091, 31.96384441141034, 30.55161384867838, 29.564890409671175, 27.238779335887745, 28.46575997413736, 27.862309945175745, 26.67645852086431, 27.10916797648568, 27.395403915717544, 28.404598171346578, 27.973075729696006, 28.789272924188147, 28.272827832551002, 25.92681241747378, 24.778747620954505, 24.62396512082558, 24.838277801073225, 23.661084591940796, 25.838047310063935, 26.869790890333366, 27.597128392306296, 27.061480455510967, 26.755869573244354, 26.593943270171486, 23.021211306902835, 21.636638272898683, 19.936419004270302, 20.538356426127613, 21.04889999521382, 21.206476475116077, 20.474327432544616, 20.730500913675513, 19.93946359899678, 17.712291313211857, 18.64911430487431, 20.298932327380292, 24.403281324875632, 23.433749785945583, 25.368204238274927, 23.37669250346416, 25.80389470323312, 19.19739761774908, 21.46835758531339, 20.384420617398426, 26.334306692738778, 22.09894233910496, 25.359592992933283, 26.130830435162466, 25.585404139918975, 22.95491894754602, 21.055773604095247, 19.51537657965822, 14.927087080211985, 15.168698621408788, 14.383734424676339, 18.093075400458435, 20.309942526601898, 20.049415003003276, 18.916706848132385, 17.73412995496482, 15.478143185394885, 15.462911347213828, 17.06556583817946, 16.276450064533826, 20.011038854979766, 21.92519228005839, 21.93205044224887, 22.963563328098783, 25.069187771767922, 22.597460974218386, 19.63699555209318, 16.49247702383932, 19.26356429088387, 18.962639345958138, 18.792142931066223, 22.94660734039426, 24.315044451797572, 18.649558650859287, 23.00657864264672, 28.49204066525045, 27.134879344897275]\n",
    "    \n",
    "    lens = list(len_to_ndcg_at_100_map.keys())\n",
    "    lens.sort()\n",
    "    X = []\n",
    "    Y = []\n",
    "    for le in lens:\n",
    "        X.append(le)\n",
    "        ans = 0.0\n",
    "        for i in len_to_ndcg_at_100_map[le]: ans += float(i)\n",
    "        ans = ans / float(len(len_to_ndcg_at_100_map[le]))\n",
    "        Y.append(ans * 100.0)\n",
    "    Y_mine = []\n",
    "    prev_5 = []\n",
    "    for i in Y:\n",
    "        prev_5.append(i)\n",
    "        if len(prev_5) > 5: del prev_5[0]\n",
    "\n",
    "        temp = 0.0\n",
    "        for j in prev_5: temp += float(j)\n",
    "        temp = float(temp) / float(len(prev_5))\n",
    "        Y_mine.append(temp)\n",
    "    print(X)\n",
    "    print(Y_mine)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(X, Y_mine, label='SVAE')\n",
    "    plt.plot(X_mvae_ml1m, Y_mvae_ml1m, label='MVAE')\n",
    "    plt.plot(X_caser_ml1m, Y_caser_ml1m, label='CASER')\n",
    "#     plt.plot(X_mvae_netflix, Y_mvae_netflix, label='MVAE')\n",
    "    # plt.plot(X_caser_netflix, Y_caser_netflix, label='CASER')\n",
    "    plt.xlabel(\"Number of items in the fold-out set\")\n",
    "    plt.ylabel(\"Average NDCG@100\")\n",
    "    plt.title(\"Movielens\")\n",
    "    plt.savefig(\"saved_plots/seq_len_vs_ndcg_ml.pdf\")\n",
    "    #plt.xscale('log', basex=10)\n",
    "    #axes = plt.gca()\n",
    "    #axes.set_xlim([10, 500])\n",
    "    #axes.set_ylim([0, 50])\n",
    "\n",
    "    leg = plt.legend(loc='best', ncol=2)\n",
    "    \n",
    "    plt.show()\n",
    "    # pass\n",
    "\n",
    "train_reader, test_reader, total_items = load_data(hyper_params)\n",
    "# print(train_reader.data[:10])\n",
    "# print(test_reader.data[:10])\n",
    "# print(test_reader.data_te[:10])\n",
    "hyper_params['total_items'] = total_items\n",
    "hyper_params['testing_batch_limit'] = test_reader.num_b\n",
    "\n",
    "file_write(hyper_params['log_file'], \"\\n\\nSimulation run on: \" + str(dt.datetime.now()) + \"\\n\\n\")\n",
    "file_write(hyper_params['log_file'], \"Data reading complete!\")\n",
    "file_write(hyper_params['log_file'], \"Number of train batches: {:4d}\".format(train_reader.num_b))\n",
    "file_write(hyper_params['log_file'], \"Number of test batches: {:4d}\".format(test_reader.num_b))\n",
    "# file_write(hyper_params['log_file'], \"Total Users: \" + str(total_users))\n",
    "file_write(hyper_params['log_file'], \"Total Items: \" + str(total_items) + \"\\n\")\n",
    "\n",
    "model = Model(hyper_params)\n",
    "if is_cuda_available: model.cuda()\n",
    "\n",
    "criterion = VAELoss(hyper_params)\n",
    "\n",
    "if hyper_params['optimizer'] == 'adagrad':\n",
    "    optimizer = torch.optim.Adagrad(\n",
    "        model.parameters(), weight_decay=hyper_params['weight_decay'], lr=hyper_params['learning_rate']\n",
    "    )\n",
    "elif hyper_params['optimizer'] == 'adadelta':\n",
    "    optimizer = torch.optim.Adadelta(\n",
    "        model.parameters(), weight_decay=hyper_params['weight_decay']\n",
    "    )\n",
    "elif hyper_params['optimizer'] == 'adam':\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), weight_decay=hyper_params['weight_decay']#, lr=hyper_params['learning_rate']\n",
    "    )\n",
    "elif hyper_params['optimizer'] == 'rmsprop':\n",
    "    optimizer = torch.optim.RMSprop(\n",
    "        model.parameters(), weight_decay=hyper_params['weight_decay']#, lr=hyper_params['learning_rate']\n",
    "    )\n",
    "\n",
    "file_write(hyper_params['log_file'], str(model))\n",
    "file_write(hyper_params['log_file'], \"\\nModel Built!\\nStarting Training...\\n\")\n",
    "\n",
    "best_val_loss = None\n",
    "\n",
    "try:\n",
    "    for epoch in range(1, hyper_params['epochs'] + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        train(train_reader)\n",
    "        \n",
    "        # Calulating the metrics on the train set\n",
    "        metrics, _ = evaluate(model, criterion, train_reader, hyper_params, True)\n",
    "        string = \"\"\n",
    "        for m in metrics: string += \" | \" + m + ' = ' + str(metrics[m])\n",
    "        string += ' (TRAIN)'\n",
    "    \n",
    "        # Calulating the metrics on the test set\n",
    "        metrics, len_to_ndcg_at_100_map = evaluate(model, criterion, test_reader, hyper_params, False)\n",
    "        string2 = \"\"\n",
    "        for m in metrics: string2 += \" | \" + m + ' = ' + str(metrics[m])\n",
    "        string2 += ' (TEST)'\n",
    "\n",
    "        ss  = '-' * 89\n",
    "        ss += '\\n| end of epoch {:3d} | time: {:5.2f}s'.format(epoch, (time.time() - epoch_start_time))\n",
    "        ss += string\n",
    "        ss += '\\n'\n",
    "        ss += '-' * 89\n",
    "        ss += '\\n| end of epoch {:3d} | time: {:5.2f}s'.format(epoch, (time.time() - epoch_start_time))\n",
    "        ss += string2\n",
    "        ss += '\\n'\n",
    "        ss += '-' * 89\n",
    "        file_write(hyper_params['log_file'], ss)\n",
    "        \n",
    "        # Plot sequence length vs NDCG@100 graph\n",
    "        # plot_len_vs_ndcg(len_to_ndcg_at_100_map)\n",
    "        \n",
    "        if not best_val_loss or metrics['loss'] <= best_val_loss:\n",
    "            with open(hyper_params['model_file_name'], 'wb') as f: torch.save(model, f)\n",
    "            best_val_loss = metrics['loss']\n",
    "\n",
    "except KeyboardInterrupt: print('Exiting from training early')\n",
    "\n",
    "# Checking metrics on best saved model\n",
    "with open(hyper_params['model_file_name'], 'rb') as f: model = torch.load(f)\n",
    "metrics, len_to_ndcg_at_100_map = evaluate(model, criterion, test_reader, hyper_params, False)\n",
    "\n",
    "string = \"\"\n",
    "for m in metrics: string += \" | \" + m + ' = ' + str(metrics[m])\n",
    "\n",
    "ss  = '=' * 89\n",
    "ss += '\\n| End of training'\n",
    "ss += string\n",
    "ss += '\\n'\n",
    "ss += '=' * 89\n",
    "file_write(hyper_params['log_file'], ss)\n",
    "\n",
    "# Plot sequence length vs NDCG@100 graph\n",
    "plot_len_vs_ndcg(len_to_ndcg_at_100_map)\n",
    "\n",
    "# Plot Traning graph\n",
    "f = open(model.hyper_params['log_file'])\n",
    "lines = f.readlines()\n",
    "lines.reverse()\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "\n",
    "for line in lines:\n",
    "    if line[:10] == 'Simulation' and len(train) > 5: break\n",
    "    elif line[:10] == 'Simulation' and len(train) <= 5: train, test = [], []\n",
    "        \n",
    "    if line[2:5] == 'end' and line[-6:-2] == 'TEST': test.append(line.strip().split(\"|\"))\n",
    "    elif line[2:5] == 'end' and line[-7:-2] == 'TRAIN': train.append(line.strip().split(\"|\"))\n",
    "\n",
    "train.reverse()\n",
    "test.reverse()\n",
    "\n",
    "train_cp, train_ndcg = [], []\n",
    "test_cp, test_ndcg = [], []\n",
    "\n",
    "for i in train:\n",
    "    train_cp.append(float(i[3].split('=')[1].strip(' ')))\n",
    "    train_ndcg.append(float(i[-3].split('=')[1].split(' ')[1]))\n",
    "    \n",
    "for i in test:\n",
    "    test_cp.append(float(i[3].split('=')[1].strip(' ')))\n",
    "    test_ndcg.append(float(i[-3].split('=')[1].split(' ')[1]))\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(train_ndcg, label='Train set')\n",
    "plt.plot(test_ndcg, label='Test set')\n",
    "plt.ylabel(\"NDCG@100\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "\n",
    "leg = plt.legend(loc='best', ncol=2)\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "223px",
    "width": "193px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Notebook contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "226px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
